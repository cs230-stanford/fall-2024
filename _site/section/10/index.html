<!DOCTYPE html>
<html>
	<head>
		<meta charset="UTF-8">
<meta http-equiv="x-ua-compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, minimum-scale=1.0">
<title>Section 9 (Week 9)</title>

	<meta name="description" content="Hyperparameter Tuning and Tensorboard">


<link rel="icon" href="/favicon.ico" type="image/x-icon">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,400i,500,500i,700,700i|Noto+Sans:400,400i,700,700i|Source+Code+Pro&amp;subset=latin-ext">
<link rel="stylesheet" href="/doks-theme/assets/css/style.css">
<script type="text/javascript" async
  src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
	</head>
	<body class="blue" data-spy="scroll" data-target=".js-scrollspy">
		
	<div class="offcanvas visible-xs">
		<ul class="offcanvas__nav">
			
				<li><a href="/syllabus">Syllabus</a></li>
			
				<li><a href="/officehours">Office Hours</a></li>
			
				<li><a href="/project">Project</a></li>
			
				<li><a href="/section">Section</a></li>
			
				<li><a href="/lecture">Lecture</a></li>
			
				<li><a href="/blog">Blog</a></li>
			
				<li><a href="/faq">FAQ</a></li>
			
		</ul><!-- /.offcanvas__nav -->
	</div><!-- /.offcanvas -->



	<header class="site-header">
		<div class="container">
			<div class="row">
				<div class="col-xs-12">
					
						<a href="/" class="site-header__logo">
							<img src="/doks-theme/assets/images/layout/logo.png">
							CS230
						</a>
					
					
						<ul class="site-header__nav hidden-xs">
							
								<li><a href="/syllabus">Syllabus</a></li>
							
								<li><a href="/officehours">Office Hours</a></li>
							
								<li><a href="/project">Project</a></li>
							
								<li><a href="/section">Section</a></li>
							
								<li><a href="/lecture">Lecture</a></li>
							
								<li><a href="/blog">Blog</a></li>
							
								<li><a href="/faq">FAQ</a></li>
							
						</ul><!-- /.site-header__nav -->
						<button class="offcanvas-toggle visible-xs">
							<span></span>
							<span></span>
							<span></span>
						</button><!-- /.offcanvas-toggle -->
					
				</div><!-- /.col -->
			</div><!-- /.row -->
		</div><!-- /.container -->
	</header><!-- /.site-header -->


		<div class="hero-subheader">
			<div class="container">
				<div class="row">
					<div class="col-md-7">
						<div class="align-container" data-mh>
							<div class="align-inner">
								
									<h1 class="hero-subheader__title">Section 9 (Week 9)</h1>
								
								
									<p class="hero-subheader__desc">Hyperparameter Tuning and Tensorboard</p>
								
								
								
							</div><!-- /.align-inner -->
						</div><!-- /.align-container -->
					</div><!-- /.col -->
						<div class="col-md-4 col-md-offset-1 hidden-xs hidden-sm">
							<div class="align-container" data-mh>
								<div class="align-inner">
									<div class="hero-subheader__author">
										<h4>Instructors</h4>
                                                                               
                                                                               
                                                                                    <div class="instructor">
                                        <a target="_blank" href="">
                    <img class="headshot" src="/doks-theme/assets/images/headshot/kian.jpg" style="text-align:center;">
                <div style="text-align:center;">Kian Katanforoosh<br>Instructor</div>
	</a>
        </div>
    

                                                                               
                                                                                    <div class="instructor">
                                        <a target="_blank" href="">
                    <img class="headshot" src="/doks-theme/assets/images/headshot/andrew.jpg" style="text-align:center;">
                <div style="text-align:center;">Andrew Ng<br>Instructor</div>
	</a>
        </div>
    

                                                                               

                                                                               

										<h4>Time and Location</h4>
                                                                                <p>In person lectures are on Tuesdays 11:30am-1:20pm. <br> Hewlett Teaching Center 200.</p>
									</div><!-- /.hero-subheader__author -->
								</div><!-- /.align-inner -->
							</div><!-- /.align-container -->
						</div><!-- /.col -->
				</div><!-- /.row -->
			</div><!-- /.container -->
		</div><!-- /.hero-subheader -->
		<div class="section">
			<div class="container">
				<div class="row">
					
					<div class="col-md-7">
						<div class="content">
							<p><strong>For the last section of the quarter, we will be dividing into students and having them provide feedback on each other’s drafts of the final report. Please come prepared!</strong></p>

<h1 id="hyperparameter-tuning">Hyperparameter Tuning</h1>

<p>Lots of hyperparameters are involved in the design of a deep neural network. Finding the best set of hyperparameters is an optimization task in of itself! In most cases, the space of possible hyperparameters is far too large for us to try all of them. Here are some strategies for solving this problem.</p>

<h3 id="random-search-and-grid-search">Random Search and Grid Search</h3>

<p>Consider the following function \(f(x,y) = g(x) + h(y)\) over parameters \(x,y\) and the maximization problem:</p>

\[\max_{x,y} f(x,y).\]

<p>Assume we only have access to \(f(x,y)\) through an <em>oracle</em> (i.e. we can evaluate \(f\) at a certain point \((x,y)\), but we do not know the functional form of \(f\)).  <strong>How could we find the optimal values of \(x\) and \(y\)?</strong></p>

<ul>
  <li>A natural idea would be to choose a range for the values of \(x\) and \(y\)  and sample a grid of points in this range.</li>
  <li>We could also evaluate a numerical gradient in the hyperparameter space.  The challenge with this method is that unlike an iteration of model training, each evaluation of hyperparameters is very costly and long, making it infeasible to try many combinations of hyperparameters.</li>
</ul>

<p>Now assume we know that</p>

\[f(x,y) = g(x) + h(y) \approx g(x).\]

<p><strong>Would grid search still be a good strategy?</strong></p>

<ul>
  <li>The function $f$ mostly depends on \(x\). Thus, a grid search strategy will waste a lot of iterations testing different values of \(y\).  If we have a finite number of evaluations of \((x,y)\), a better strategy would be randomly sampling  \(x\) and \(y\) in a certain range, that way each sample tests a different value of each hyperparameter.</li>
</ul>

<table class="image">
<caption align="bottom"><small>An illustration of how random search can improve on grid search of hyperparameters.  'This failure of grid search is the rule rather than the exception in high dimensional hyperparameter optimization.' (Bergstra &amp; Bengio, 2011). (<a href="http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf">source</a>)</small></caption> 
<tr><td><img src="/doks-theme/assets/images/section/7/random-grid.png" style="width: 100%" /></td></tr>
</table>

<p><strong>What are weaknesses and assumptions of random search?</strong></p>

<ul>
  <li>Random search assumes that the hyperparameters are uncorrelated. Ideally, we would sample hyperparameters from a joint distribution that takes into account this understanding. Additionally, it doesn’t use the results of previous iterations to inform how we choose parameter values for future iterations. This is the motivation behind Bayesian optimization.</li>
</ul>

<h3 id="bayesian-optimization">Bayesian Optimization</h3>

<p>Bayesian inference is a form of statistical inference that uses Bayes’ Theorem to incorporate prior knowledge when performing estimation.  Bayes’ Theorem is a simple, yet extremely powerful, formula relating conditional and joint distributions of random variables. Let \(X\) be the random variable representing the quality of our model and \(\theta\) the random variable representing our hyperparameters. Then Bayes’ Rule relates the distributions \(p(\theta \mid X)\) (posterior), \(p(X\mid\theta)\) (likelihood), \(p(\theta)\) (prior) and \(p(X)\) (marginal) as:</p>

\[p(\theta\mid M) = \frac{p(M \mid \theta)p(\theta)}{p(M)}\]

<p><strong>How could we use Bayes’ Rule to improve random search?</strong></p>

<ul>
  <li>By using a prior on our hyperparameters, we can incorporate prior knowledge into our optimizer. By sampling from the posterior distribution instead of a uniform distribution, we can incorporate the results of our previous samples to improve our search process.</li>
</ul>

<p>Let’s reconsider the optimization problem of finding the maximum of \(f(x,y)\).  A Bayesian optimization strategy would:</p>

<ol>
  <li>Initialize a prior on the parameters \(x\) and \(y\).</li>
  <li>Sample an point \((x,y)\) to evaluate \(f\) with.</li>
  <li>Use the result of \(f(x,y)\) to update the posterior on \(x,y\).</li>
  <li>Repeat 2 and 3.</li>
</ol>

<p>The goal is to guess the function, even if we cannot know its true form. By adding a new data point at each iteration, the algorithm can guess the function more accurately, and more intelligently choose the next point to evaluate to improve its guess. A Gaussian process is used to infer the function from samples of its inputs and outputs. It also provides a distribution over the possible functions given the observed data.</p>

<p>Let’s consider an example: say we want to find the minimum of some function whose expression is unknown. The function has one input and one output, and we’ve taken four different samples (the blue points).</p>

<table class="image">
<caption align="bottom"><small>A Gaussian process distribution, given four sampled data points in blue. (<a href="https://www.quora.com/How-does-Bayesian-optimization-work">source</a>)</small></caption> 
<tr><td><img src="/doks-theme/assets/images/section/8/bayes.png" style="width: 100%" /></td></tr>
</table>

<p>The Gaussian process provides a distribution of continuous functions that fit these points, which is represented in green. The darker the shade, the more likely the true function is within that region. The green line is the mean guess of the “true” function, and each band of green is a half standard deviation of the Gaussian process distribution.</p>

<p>Now, given this useful guess, what point should we evaluate next? We have two possible options:</p>

<ul>
  <li><strong>Exploitation:</strong> Evaluate a point that, based on our current model of likely functions, will yield a low output value. For instance, 1.0 could be an option in the above graph.</li>
  <li><strong>Exploration:</strong> Get a datapoint on an area we’re most unsure about. In the graph above, we could focus on the zone between .65 and .75, rather than between .15 and .25, since we have a pretty good idea as to what’s going on in the latter zone. That way, we will will be able to reduce the variance of future guesses.</li>
</ul>

<p>Balancing these two is the <em>exploration-exploitation</em> trade-off. We choose between the two strategies using an acquisition function.</p>

<table class="image">
<caption align="bottom"><small>With each iteration 'the algorithm balances its needs of exploration and exploitation' (Nogueira). (<a href="https://github.com/fmfn/BayesianOptimization">source</a>)</small></caption> 
<tr><td><img src="/doks-theme/assets/images/section/7/bayesopt.gif" style="width: 100%" /></td></tr>
</table>

<p>If you’re interested in learning more or trying out the optimizer, here is a good <a href="https://github.com/fmfn/BayesianOptimization">Python code base</a> for using Bayesian Optimization with Gaussian processes.</p>

<h1 id="tensorboard">TensorBoard</h1>

<p>TensorBoard is a great way to track and visualize neural network performance over time as it trains!</p>

<table class="image">
<caption align="bottom"><small>TensorBoard. (<a href="https://www.tensorflow.org/guide/summaries_and_tensorboard">source</a>)</small></caption> 
<tr><td><img src="/doks-theme/assets/images/section/8/tboard.png" style="width: 100%" /></td></tr>
</table>

<p>TensorBoard was built for TensorFlow, but can also be used with PyTorch using the TensorBoardX library.</p>

<p>Let’s walk through the AWS TensorBoard code and see it in action on an AWS instance.  Instructions <a href="https://docs.aws.amazon.com/dlami/latest/devguide/tutorial-tensorboard.html">here</a>. Make sure to perform steps 5 and 6 (opening a port in your AWS security settings, and setting up an SSH tunnel to your machine).</p>

<h2 id="running-tensorboard-locally">Running TensorBoard Locally</h2>
<p>We’ve also created a few Tensorflow 2/Keras examples that you can run on your local machine. These examples demonstrate how to show how to display loss curves, images, and figures like confusion matrices for the MNIST classification task on your local machine.</p>

<h3 id="setup">Setup</h3>
<p>You’ll need a couple of python packages to get started with these examples. Run these commands
to create a virtual environment for this tutorial and start a TensorBoard server:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>virtualenv <span class="nt">-p</span> python3 .venv
<span class="nb">source</span> .venv/bin/activate
pip <span class="nb">install </span>numpy matplotlib tensorflow tensorboard scikit-learn
tensorboard <span class="nt">--logdir</span> logs &amp;
</code></pre></div></div>
<p>Running <code class="language-plaintext highlighter-rouge">tensorboard --logdir logs &amp;</code> will create a directory called <code class="language-plaintext highlighter-rouge">logs</code> where TensorBoard
will store the metrics from your training runs and start a TensorBoard server as a background process.
Open the TensorBoard dashboard by going to <code class="language-plaintext highlighter-rouge">localhost:6006</code> in your browser (or whichever port number your server is running on).</p>

<h3 id="plotting-losses-accuracies-and-weight-distributions">Plotting losses, accuracies, and weight distributions</h3>

<p>For this first example we’ll plot train and val loss and accuracy curves in addition to histograms of the weights of our network as it trains. To do this, we import the TensorBoard callback,
configure where it will store the training logs (we name this directory as a formatted string
representing the current time), and pass this callback to <code class="language-plaintext highlighter-rouge">model.fit()</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="n">TensorBoard</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>

<span class="n">time</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">().</span><span class="n">strftime</span><span class="p">(</span><span class="s">"%Y%m%d-%H%M%S"</span><span class="p">)</span>
<span class="n">log_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"logs/</span><span class="si">{</span><span class="n">time</span><span class="si">}</span><span class="s">"</span>
<span class="n">tensorboard</span> <span class="o">=</span> <span class="n">TensorBoard</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">histogram_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># added
</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">tensorboard</span><span class="p">]</span>
    <span class="p">)</span>
</code></pre></div></div>

<table class="image">
<caption align="bottom"><small>We can see plots of the train and val losses and accuracies by navigating to the 'Scalars' tab of the TensorBoard dashboard at 'localhost:6000' in a browser.

 (<a href="">source</a>)</small></caption> 
<tr><td><img src="/doks-theme/assets/images/section/8/losses.png" style="width: 100%" /></td></tr>
</table>

<p>By setting <code class="language-plaintext highlighter-rouge">histogram_freq=1</code> in the TensorBoard callback constructor, we can track the
distributions of the weights in each layer at each epoch.</p>

<table class="image">
<caption align="bottom"><small>The 'Histograms' tab shows histograms of the weights in each layer at each epoch. (<a href="">source</a>)</small></caption> 
<tr><td><img src="/doks-theme/assets/images/section/8/hist.png" style="width: 100%" /></td></tr>
</table>

<h3 id="logging-images">Logging Images</h3>
<p>This next example shows how to use <code class="language-plaintext highlighter-rouge">tf.summary</code> to log image data for visualization. Here we simply log the first five examples in the training set so that we can inspect them in the ‘Images’ tab of the TensorBoard dashboard.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="n">TensorBoard</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span> <span class="c1"># added
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> <span class="c1"># added
</span><span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="c1"># added
</span>
<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>

<span class="n">time</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">().</span><span class="n">strftime</span><span class="p">(</span><span class="s">"%Y%m%d-%H%M%S"</span><span class="p">)</span>
<span class="n">log_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"logs/</span><span class="si">{</span><span class="n">time</span><span class="si">}</span><span class="s">"</span>
<span class="n">tensorboard</span> <span class="o">=</span> <span class="n">TensorBoard</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">histogram_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Visualize image, added
</span><span class="n">images</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">],</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># batch_size first
</span><span class="n">file_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="n">create_file_writer</span><span class="p">(</span><span class="n">log_dir</span><span class="p">)</span>
<span class="k">with</span> <span class="n">file_writer</span><span class="p">.</span><span class="n">as_default</span><span class="p">():</span>
	<span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="n">image</span><span class="p">(</span><span class="s">"Training Data"</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">max_outputs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>

<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> 
    <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> 
    <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> 
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">tensorboard</span><span class="p">]</span>
<span class="p">)</span>
</code></pre></div></div>
<table class="image">

<tr><td><img src="/doks-theme/assets/images/section/8/data.png" style="width: 100%" /></td></tr>
</table>

<h3 id="custom-logging-callbacks">Custom Logging Callbacks</h3>
<p>The previous example showed how to log images from the training set at the beginning
of training, but it would be more helpful to be able to log images and figures
continusouly over the course of training. For example, if we were training a GAN,
monitoring the loss curves of the generator and discriminator over time wouldn’t give much
insight into the performance of the model, and it would be much more
illuminating to be able to view samples generated over time to see if sample quality
is improving. Likewise, for a classification task like MNIST digit classification,
being able to see the evolution of confusion matrices or ROC curves over time can give
a better sense of model performance than a single number like accuracy. Here we show
how to plot confusion matrices at the end of each epoch.</p>

<p>We can define custom logging behavior that executes at fixed intervals during training
using a <code class="language-plaintext highlighter-rouge">LambdaCallback</code>. In the code below, we define a function 
<code class="language-plaintext highlighter-rouge">log_confusion_matrix</code> that generates the model’s predictions on the val set
and creates a confusion matrix image using the <code class="language-plaintext highlighter-rouge">sklearn.metrics.confusion_matrix()</code> function,
and create a callback that plots the confusion matrix at the end of every epoch
with <code class="language-plaintext highlighter-rouge">cm_callback = LambdaCallback(on_epoch_end=log_confusion_matrix)</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="n">TensorBoard</span><span class="p">,</span> <span class="n">LambdaCallback</span> <span class="c1"># added
</span>
<span class="kn">import</span> <span class="nn">io</span> <span class="c1"># added
</span><span class="kn">import</span> <span class="nn">itertools</span> <span class="c1"># added
</span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span>

<span class="c1"># Added
</span><span class="k">def</span> <span class="nf">plot_to_image</span><span class="p">(</span><span class="n">fig</span><span class="p">):</span>
	<span class="n">buf</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="n">BytesIO</span><span class="p">()</span>
	<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">buf</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s">'png'</span><span class="p">)</span>
	<span class="n">plt</span><span class="p">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
	<span class="n">buf</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
	<span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">decode_png</span><span class="p">(</span><span class="n">buf</span><span class="p">.</span><span class="n">getvalue</span><span class="p">(),</span> <span class="n">channels</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
	<span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">img</span>

<span class="c1"># Added
</span><span class="k">def</span> <span class="nf">plot_confusion_matrix</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">class_names</span><span class="p">):</span>
	<span class="n">figure</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
	<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s">'nearest'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">Blues</span><span class="p">)</span>
	<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Confusion matrix"</span><span class="p">)</span>
	<span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">()</span>
	<span class="n">tick_marks</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">class_names</span><span class="p">))</span>
	<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">class_names</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
	<span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">class_names</span><span class="p">)</span>

	<span class="n">cm</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">around</span><span class="p">(</span><span class="n">cm</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float'</span><span class="p">)</span> <span class="o">/</span> <span class="n">cm</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">decimals</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

	<span class="n">threshold</span> <span class="o">=</span> <span class="n">cm</span><span class="p">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">/</span> <span class="mf">2.</span>
	<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">itertools</span><span class="p">.</span><span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])):</span>
		<span class="n">color</span> <span class="o">=</span> <span class="s">"white"</span> <span class="k">if</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span> <span class="k">else</span> <span class="s">"black"</span>
		<span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s">"center"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>

	<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
	<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'True label'</span><span class="p">)</span>
	<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Predicted label'</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">figure</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_train</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">/</span> <span class="mf">255.0</span>

<span class="n">time</span> <span class="o">=</span> <span class="n">datetime</span><span class="p">.</span><span class="n">datetime</span><span class="p">.</span><span class="n">now</span><span class="p">().</span><span class="n">strftime</span><span class="p">(</span><span class="s">"%Y%m%d-%H%M%S"</span><span class="p">)</span>
<span class="n">log_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"logs/</span><span class="si">{</span><span class="n">time</span><span class="si">}</span><span class="s">"</span>
<span class="n">tensorboard</span> <span class="o">=</span> <span class="n">TensorBoard</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="n">log_dir</span><span class="p">,</span> <span class="n">histogram_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Added
</span><span class="n">file_writer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="n">create_file_writer</span><span class="p">(</span><span class="n">log_dir</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">log_confusion_matrix</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
	<span class="n">test_pred_raw</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
	<span class="n">test_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test_pred_raw</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

	<span class="n">cm</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_pred</span><span class="p">)</span>
	<span class="n">figure</span> <span class="o">=</span> <span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)))</span>
	<span class="n">cm_image</span> <span class="o">=</span> <span class="n">plot_to_image</span><span class="p">(</span><span class="n">figure</span><span class="p">)</span>
	<span class="k">with</span> <span class="n">file_writer</span><span class="p">.</span><span class="n">as_default</span><span class="p">():</span>
		<span class="n">tf</span><span class="p">.</span><span class="n">summary</span><span class="p">.</span><span class="n">image</span><span class="p">(</span><span class="s">"Confusion Matrix"</span><span class="p">,</span> <span class="n">cm_image</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
<span class="n">cm_callback</span> <span class="o">=</span> <span class="n">LambdaCallback</span><span class="p">(</span><span class="n">on_epoch_end</span><span class="o">=</span><span class="n">log_confusion_matrix</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
    <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
<span class="p">])</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>

<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> 
    <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> 
    <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> 
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">tensorboard</span><span class="p">,</span> <span class="n">cm_callback</span><span class="p">]</span> <span class="c1"># added
</span><span class="p">)</span>
</code></pre></div></div>
<table class="image">
<caption align="bottom"><small>LambdaCallbacks allow us to view the history of confusion matrices summarizing our model's performance on the val set over time (<a href="">source</a>)</small></caption> 
<tr><td><img src="/doks-theme/assets/images/section/8/confusion.png" style="width: 100%" /></td></tr>
</table>

						</div><!-- /.content -->
					</div><!-- /.col -->
					<div class="col-md-4 col-md-offset-1">
						<div class="sections-list-wrapper">
							<div class="sections-list js-sections js-affix js-scrollspy hidden-xs hidden-sm"></div><!-- /.sections-list -->
						</div>
					</div><!-- /.col -->
					
				</div><!-- /.row -->
			</div><!-- /.container -->
		</div><!-- /.section -->
		
		<div class="js-footer-area">
			
			
	<footer class="site-footer">
		<div class="container">
			<div class="row">
				<div class="col-sm-6">
					
					
						<!-- <hr> -->
						<p class="site-footer__copyright">Copyright &copy; 2024. - Stanford University <br>All rights reserved.</p>
					
				</div><!-- /.col -->
				
			</div><!-- /.row -->
		</div><!-- /.container -->
	</footer><!-- /.site-footer -->


<script src="/doks-theme/assets/js/vendor/jquery.min.js"></script>
<script type="text/javascript" src="/doks-theme/assets/js/vendor/bootstrap/affix.min.js"></script>
<script type="text/javascript" src="/doks-theme/assets/js/vendor/bootstrap/scrollspy.min.js"></script>
<script type="text/javascript" src="/doks-theme/assets/js/vendor/matchHeight.min.js"></script>
<script type="text/javascript" src="/doks-theme/assets/js/scripts.min.js"></script>

		</div><!-- /.js-footer-area -->
	</body>
</html>
